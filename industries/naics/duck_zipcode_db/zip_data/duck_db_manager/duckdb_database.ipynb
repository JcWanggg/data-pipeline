{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDBManager example usages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database database/us_economic_data.duckdb does not exist. Creating new database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing DataEntry CSV file(s): 100%|██████████| 49/49 [00:25<00:00,  1.95it/s]\n",
      "Importing DimNaics CSV file(s): 100%|██████████| 1/1 [00:00<00:00, 178.61it/s]\n",
      "Importing DimYear CSV file(s): 100%|██████████| 1/1 [00:00<00:00, 138.21it/s]\n",
      "Importing DimZipCode CSV file(s): 100%|██████████| 1/1 [00:00<00:00, 31.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import duckdb_manager as ddb\n",
    "\n",
    "db_manager = ddb.DuckDBManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: If the program can't find the duck db file, it will automaticlally recreate the database using the 'import_all_csv_files'. \n",
    "\n",
    "### This functionality will not work if you don't have the necessary csv files, so if for whatever reason you don't have the data, you can just run the 'populate_database' notebook file to get the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since github does not allow users to upload files larger than 100mb, the duckdb database has to split into seperate csv files. However, I don't recommend using the CSV files directly as pandas dataframes since performance becomes an issue whenever CSV files are too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting DataEntry CSV files: 100%|██████████| 12/12 [00:54<00:00,  4.55s/it]\n"
     ]
    }
   ],
   "source": [
    "db_manager.export_to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'check_row_length' function takes in a string and spits out the number of rows in the table specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataEntry number of rows: 36216155\n",
      "DimZipCode number of rows: 39331\n",
      "DimYear number of rows: 12\n",
      "DimNaics number of rows: 2216\n"
     ]
    }
   ],
   "source": [
    "print(f\"DataEntry number of rows: {db_manager.check_row_length('DataEntry')}\")\n",
    "print(f\"DimZipCode number of rows: {db_manager.check_row_length('DimZipCode')}\")\n",
    "print(f\"DimYear number of rows: {db_manager.check_row_length('DimYear')}\")\n",
    "print(f\"DimNaics number of rows: {db_manager.check_row_length('DimNaics')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to nested zip folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckdb\n",
      "  Downloading duckdb-1.0.0-cp39-cp39-win_amd64.whl.metadata (781 bytes)\n",
      "Downloading duckdb-1.0.0-cp39-cp39-win_amd64.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/10.0 MB 6.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/10.0 MB 11.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.1/10.0 MB 17.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.8/10.0 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.9/10.0 MB 19.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.0/10.0 MB 21.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.9/10.0 MB 21.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.8/10.0 MB 20.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.1/10.0 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.2/10.0 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/10.0 MB 23.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 21.9 MB/s eta 0:00:00\n",
      "Installing collected packages: duckdb\n",
      "Successfully installed duckdb-1.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GeoIDs:   0%|          | 53/39331 [00:33<6:48:09,  1.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\sjchu\\.pyenv\\pyenv-win\\versions\\3.9.6\\lib\\multiprocessing\\pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 853\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m db_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabase/us_economic_data.duckdb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m db_exporter \u001b[38;5;241m=\u001b[39m dex\u001b[38;5;241m.\u001b[39mDataExporter(export_dir\u001b[38;5;241m=\u001b[39mexport_dir, db_path\u001b[38;5;241m=\u001b[39mdb_path)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mdb_exporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_geo_nested_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sjchu\\OneDrive\\Documents\\GitHub\\data-pipeline\\industries\\naics\\duck_zipcode_db\\zip_data\\duck_db_manager\\dataexporter.py:43\u001b[0m, in \u001b[0;36mDataExporter.export_geo_nested_csv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [(geo_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_dir) \u001b[38;5;28;01mfor\u001b[39;00m geo_id, \u001b[38;5;129;01min\u001b[39;00m geo_ids]\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Using imap instead of map to handle updates correctly with tqdm\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export_geo_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProcessing GeoIDs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sjchu\\.pyenv\\pyenv-win\\versions\\3.9.6\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sjchu\\.pyenv\\pyenv-win\\versions\\3.9.6\\lib\\multiprocessing\\pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 858\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    860\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[1;32mc:\\Users\\sjchu\\.pyenv\\pyenv-win\\versions\\3.9.6\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import dataexporter as dex\n",
    "import os\n",
    "export_dir='database/nested_zip'\n",
    "db_path='database/us_economic_data.duckdb'\n",
    "db_exporter = dex.DataExporter(export_dir=export_dir, db_path=db_path)\n",
    "db_exporter.export_geo_nested_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'get_schema' gives us the database schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_manager.get_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'execute_query' function allows you to create a custom query and get a dataframe back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionException",
     "evalue": "Connection Error: Connection has already been closed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m \u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m    SELECT \u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m        *\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m    LIMIT 10\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mdb_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sjchu\\OneDrive\\Documents\\GitHub\\data-pipeline\\industries\\naics\\duck_zipcode_db\\zip_data\\duck_db_manager\\duckdb_manager.py:184\u001b[0m, in \u001b[0;36mDuckDBManager.execute_query\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query):\n\u001b[1;32m--> 184\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m     df \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mfetchdf()\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mConnectionException\u001b[0m: Connection Error: Connection has already been closed"
     ]
    }
   ],
   "source": [
    "query = \"\"\" \n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        DimZipCode\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "db_manager.execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>GeoID</th>\n",
       "      <th>NaicsCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Establishments</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Payroll</th>\n",
       "      <th>IndustryLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33991666</td>\n",
       "      <td>01007</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33991667</td>\n",
       "      <td>01451</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33991668</td>\n",
       "      <td>01473</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33991669</td>\n",
       "      <td>01720</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33991670</td>\n",
       "      <td>01770</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21745</th>\n",
       "      <td>35596577</td>\n",
       "      <td>08540</td>\n",
       "      <td>99</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21746</th>\n",
       "      <td>35596578</td>\n",
       "      <td>08618</td>\n",
       "      <td>99</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>35596579</td>\n",
       "      <td>08701</td>\n",
       "      <td>99</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21748</th>\n",
       "      <td>35596580</td>\n",
       "      <td>08831</td>\n",
       "      <td>99</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21749</th>\n",
       "      <td>35596581</td>\n",
       "      <td>08854</td>\n",
       "      <td>99</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21750 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        EntryID  GeoID NaicsCode  Year  Establishments  Employees  Payroll  \\\n",
       "0      33991666  01007        11  2021               3          0        0   \n",
       "1      33991667  01451        11  2021               4          0        0   \n",
       "2      33991668  01473        11  2021               5          0        0   \n",
       "3      33991669  01720        11  2021               3          0        0   \n",
       "4      33991670  01770        11  2021               3          0        0   \n",
       "...         ...    ...       ...   ...             ...        ...      ...   \n",
       "21745  35596577  08540        99  2021               3          0        0   \n",
       "21746  35596578  08618        99  2021               4          0        0   \n",
       "21747  35596579  08701        99  2021              10          0        0   \n",
       "21748  35596580  08831        99  2021               3          0        0   \n",
       "21749  35596581  08854        99  2021               5          0        0   \n",
       "\n",
       "       IndustryLevel  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  2  \n",
       "4                  2  \n",
       "...              ...  \n",
       "21745              2  \n",
       "21746              2  \n",
       "21747              2  \n",
       "21748              2  \n",
       "21749              2  \n",
       "\n",
       "[21750 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_manager.filter_by_year_zip_industry(zip_prefix=0, industry_level=2, year=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>GeoID</th>\n",
       "      <th>NaicsCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Establishments</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Payroll</th>\n",
       "      <th>IndustryLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35597371</td>\n",
       "      <td>91327</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35597372</td>\n",
       "      <td>91337</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35597373</td>\n",
       "      <td>91603</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35597374</td>\n",
       "      <td>91324</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>1423</td>\n",
       "      <td>15910</td>\n",
       "      <td>479071</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35597375</td>\n",
       "      <td>91326</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>484</td>\n",
       "      <td>4053</td>\n",
       "      <td>116138</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35597376</td>\n",
       "      <td>91329</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35597377</td>\n",
       "      <td>91331</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>832</td>\n",
       "      <td>12004</td>\n",
       "      <td>473834</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35597378</td>\n",
       "      <td>91333</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>35597379</td>\n",
       "      <td>91340</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>665</td>\n",
       "      <td>10172</td>\n",
       "      <td>391684</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35597380</td>\n",
       "      <td>91322</td>\n",
       "      <td>00</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EntryID  GeoID NaicsCode  Year  Establishments  Employees  Payroll  \\\n",
       "0  35597371  91327        00  2012               6          0        0   \n",
       "1  35597372  91337        00  2012               3          0      200   \n",
       "2  35597373  91603        00  2012               4          0      186   \n",
       "3  35597374  91324        00  2012            1423      15910   479071   \n",
       "4  35597375  91326        00  2012             484       4053   116138   \n",
       "5  35597376  91329        00  2012               3          0        0   \n",
       "6  35597377  91331        00  2012             832      12004   473834   \n",
       "7  35597378  91333        00  2012               2          0        0   \n",
       "8  35597379  91340        00  2012             665      10172   391684   \n",
       "9  35597380  91322        00  2012              12          0     1600   \n",
       "\n",
       "   IndustryLevel  \n",
       "0              2  \n",
       "1              2  \n",
       "2              2  \n",
       "3              2  \n",
       "4              2  \n",
       "5              2  \n",
       "6              2  \n",
       "7              2  \n",
       "8              2  \n",
       "9              2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\" \n",
    "    SELECT \n",
    "        *\n",
    "    FROM\n",
    "        DataEntry\n",
    "    WHERE\n",
    "        NaicsCode = '00'\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "db_manager.execute_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Connect to DuckDB\n",
    "conn = duckdb.connect(database='database/us_economic_data.duckdb', read_only=False)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch unique GeoIDs\n",
    "cursor.execute(\"SELECT DISTINCT GeoID FROM DataEntry\")\n",
    "geo_ids = cursor.fetchall()\n",
    "\n",
    "base_dir = \"/nested_zip\"\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "# Create main directories for each GeoID\n",
    "for (geo_id,) in geo_ids:\n",
    "    geo_path = os.path.join(base_dir, geo_id)\n",
    "    os.makedirs(geo_path, exist_ok=True)\n",
    "    \n",
    "    # Fetch unique combinations of Year and IndustryLevel for each GeoID\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT DISTINCT Year, IndustryLevel\n",
    "    FROM DataEntry\n",
    "    WHERE GeoID = ?\n",
    "    \"\"\", (geo_id,))\n",
    "    combinations = cursor.fetchall()\n",
    "\n",
    "    # Create CSV files for each combination of Year and IndustryLevel within the GeoID directory\n",
    "    for year, industry_level in combinations:\n",
    "        csv_file_name = f\"data_{year}_{industry_level}.csv\"\n",
    "        csv_file_path = os.path.join(geo_path, csv_file_name)\n",
    "\n",
    "        # Fetch data for each combination\n",
    "        cursor.execute(\"\"\"\n",
    "        SELECT GeoID, Establishments, \"Employees\", \"Payroll\" FROM DataEntry\n",
    "        WHERE GeoID = ? AND Year = ? AND IndustryLevel = ?\n",
    "        \"\"\", (geo_id, year, industry_level))\n",
    "        data_entries = cursor.fetchall()\n",
    "\n",
    "        # Write data to the CSV file\n",
    "        with open(csv_file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Zip\", \"Establishments\", \"Employees\", \"Payroll\"])\n",
    "            writer.writerows(data_entries)\n",
    "\n",
    "# Close the database connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 41\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Fetch data for each combination\u001b[39;00m\n\u001b[1;32m     37\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124mSELECT GeoID, Establishments, Employees, Payroll FROM DataEntry\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124mWHERE GeoID = ? AND Year = ? AND IndustryLevel = ?\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m, (geo_id, year, industry_level))\n\u001b[0;32m---> 41\u001b[0m data_entries \u001b[38;5;241m=\u001b[39m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetchall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Write data to the CSV file\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(csv_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Connect to DuckDB\n",
    "conn = duckdb.connect(database='database/us_economic_data.duckdb', read_only=False)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the base directory for nested ZIP directories\n",
    "base_dir = \"./nested_zip\"\n",
    "os.makedirs(base_dir, exist_ok=True)  # Ensure the base directory exists\n",
    "\n",
    "# Fetch unique GeoIDs\n",
    "cursor.execute(\"SELECT DISTINCT GeoID FROM DataEntry\")\n",
    "geo_ids = cursor.fetchall()\n",
    "\n",
    "# Create nested directories for each digit of each GeoID\n",
    "for (geo_id,) in geo_ids:\n",
    "    # Create a path by nesting directories for each digit of the GeoID\n",
    "    path_components = [base_dir] + list(geo_id)\n",
    "    geo_path = os.path.join(*path_components)\n",
    "    os.makedirs(geo_path, exist_ok=True)\n",
    "    \n",
    "    # Fetch unique combinations of Year and IndustryLevel for this GeoID\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT DISTINCT Year, IndustryLevel FROM DataEntry\n",
    "        WHERE GeoID = ?\n",
    "    \"\"\", (geo_id,))\n",
    "    combinations = cursor.fetchall()\n",
    "\n",
    "    # Create CSV files for each combination of Year and IndustryLevel in the deepest directory\n",
    "    for year, industry_level in combinations:\n",
    "        csv_file_name = f\"data_{year}_{industry_level}.csv\"\n",
    "        csv_file_path = os.path.join(geo_path, csv_file_name)\n",
    "\n",
    "        # Fetch data for each combination\n",
    "        cursor.execute(\"\"\"\n",
    "        SELECT GeoID, Establishments, Employees, Payroll FROM DataEntry\n",
    "        WHERE GeoID = ? AND Year = ? AND IndustryLevel = ?\n",
    "        \"\"\", (geo_id, year, industry_level))\n",
    "        data_entries = cursor.fetchall()\n",
    "\n",
    "        # Write data to the CSV file\n",
    "        with open(csv_file_path, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Zip\", \"Establishments\", \"Employees\", \"Payroll\"])\n",
    "            writer.writerows(data_entries)\n",
    "\n",
    "# Close the database connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
